{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRIKAR-SILUVERI/NLP/blob/main/Lab8_2_Srikar_2403A52240_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **N-Gram Language Model Implementation and Evaluation – Perplexity**"
      ],
      "metadata": {
        "id": "D6D7Rt2YQt8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1 — Create Dataset**"
      ],
      "metadata": {
        "id": "cSXT9_MzQz9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuCXAaaXQpx7"
      },
      "outputs": [],
      "source": [
        "D1 = \"Artificial intelligence is transforming modern healthcare systems\"\n",
        "D2 = \"Machine learning algorithms improve prediction accuracy in medicine\"\n",
        "D3 = \"Deep neural networks require large computational resources\"\n",
        "D4 = \"Natural language processing helps computers understand human language\"\n",
        "D5 = \"Medical diagnosis systems use probabilistic models for decision making\"\n",
        "D6 = \"Researchers analyze genomic data using advanced algorithms\"\n",
        "D7 = \"Clinical decision support systems assist doctors in hospitals\"\n",
        "D8 = \"Big data analytics enables faster disease detection\"\n",
        "D9 = \"Statistical models are essential for healthcare research\"\n",
        "D10 = \"Computational linguistics combines computer science and linguistics\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uni-Gram Counts**"
      ],
      "metadata": {
        "id": "Yc1ZeRE_SCl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Combine the text from D1 to D10\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Vocabulary size\n",
        "V = len(unigram_counts)\n",
        "print(\"Vocabulary Size =\", V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfCNBOo9SWUd",
        "outputId": "53600c7b-789e-4562-b809-18830eda44a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "systems: 3\n",
            "healthcare: 2\n",
            "algorithms: 2\n",
            "in: 2\n",
            "computational: 2\n",
            "language: 2\n",
            "models: 2\n",
            "for: 2\n",
            "decision: 2\n",
            "data: 2\n",
            "linguistics: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "is: 1\n",
            "transforming: 1\n",
            "modern: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "improve: 1\n",
            "prediction: 1\n",
            "accuracy: 1\n",
            "medicine: 1\n",
            "deep: 1\n",
            "neural: 1\n",
            "networks: 1\n",
            "require: 1\n",
            "large: 1\n",
            "resources: 1\n",
            "natural: 1\n",
            "processing: 1\n",
            "helps: 1\n",
            "computers: 1\n",
            "understand: 1\n",
            "human: 1\n",
            "medical: 1\n",
            "diagnosis: 1\n",
            "use: 1\n",
            "probabilistic: 1\n",
            "making: 1\n",
            "researchers: 1\n",
            "analyze: 1\n",
            "genomic: 1\n",
            "using: 1\n",
            "advanced: 1\n",
            "clinical: 1\n",
            "support: 1\n",
            "assist: 1\n",
            "doctors: 1\n",
            "hospitals: 1\n",
            "big: 1\n",
            "analytics: 1\n",
            "enables: 1\n",
            "faster: 1\n",
            "disease: 1\n",
            "detection: 1\n",
            "statistical: 1\n",
            "are: 1\n",
            "essential: 1\n",
            "research: 1\n",
            "combines: 1\n",
            "computer: 1\n",
            "science: 1\n",
            "and: 1\n",
            "Vocabulary Size = 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "ePtGXHi_SgHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r60_FHCDSjQG",
        "outputId": "04959725-2a65-4118-cbfe-4bfd01112663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "artificial intelligence: 1\n",
            "intelligence is: 1\n",
            "is transforming: 1\n",
            "transforming modern: 1\n",
            "modern healthcare: 1\n",
            "healthcare systems: 1\n",
            "systems machine: 1\n",
            "machine learning: 1\n",
            "learning algorithms: 1\n",
            "algorithms improve: 1\n",
            "improve prediction: 1\n",
            "prediction accuracy: 1\n",
            "accuracy in: 1\n",
            "in medicine: 1\n",
            "medicine deep: 1\n",
            "deep neural: 1\n",
            "neural networks: 1\n",
            "networks require: 1\n",
            "require large: 1\n",
            "large computational: 1\n",
            "computational resources: 1\n",
            "resources natural: 1\n",
            "natural language: 1\n",
            "language processing: 1\n",
            "processing helps: 1\n",
            "helps computers: 1\n",
            "computers understand: 1\n",
            "understand human: 1\n",
            "human language: 1\n",
            "language medical: 1\n",
            "medical diagnosis: 1\n",
            "diagnosis systems: 1\n",
            "systems use: 1\n",
            "use probabilistic: 1\n",
            "probabilistic models: 1\n",
            "models for: 1\n",
            "for decision: 1\n",
            "decision making: 1\n",
            "making researchers: 1\n",
            "researchers analyze: 1\n",
            "analyze genomic: 1\n",
            "genomic data: 1\n",
            "data using: 1\n",
            "using advanced: 1\n",
            "advanced algorithms: 1\n",
            "algorithms clinical: 1\n",
            "clinical decision: 1\n",
            "decision support: 1\n",
            "support systems: 1\n",
            "systems assist: 1\n",
            "assist doctors: 1\n",
            "doctors in: 1\n",
            "in hospitals: 1\n",
            "hospitals big: 1\n",
            "big data: 1\n",
            "data analytics: 1\n",
            "analytics enables: 1\n",
            "enables faster: 1\n",
            "faster disease: 1\n",
            "disease detection: 1\n",
            "detection statistical: 1\n",
            "statistical models: 1\n",
            "models are: 1\n",
            "are essential: 1\n",
            "essential for: 1\n",
            "for healthcare: 1\n",
            "healthcare research: 1\n",
            "research computational: 1\n",
            "computational linguistics: 1\n",
            "linguistics combines: 1\n",
            "combines computer: 1\n",
            "computer science: 1\n",
            "science and: 1\n",
            "and linguistics: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "oakce0FZSsgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate trigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate trigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "# Print the trigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yucEqbP2SvxA",
        "outputId": "7e42f200-ad2d-4986-800d-c082daff5edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "artificial intelligence is: 1\n",
            "intelligence is transforming: 1\n",
            "is transforming modern: 1\n",
            "transforming modern healthcare: 1\n",
            "modern healthcare systems: 1\n",
            "healthcare systems machine: 1\n",
            "systems machine learning: 1\n",
            "machine learning algorithms: 1\n",
            "learning algorithms improve: 1\n",
            "algorithms improve prediction: 1\n",
            "improve prediction accuracy: 1\n",
            "prediction accuracy in: 1\n",
            "accuracy in medicine: 1\n",
            "in medicine deep: 1\n",
            "medicine deep neural: 1\n",
            "deep neural networks: 1\n",
            "neural networks require: 1\n",
            "networks require large: 1\n",
            "require large computational: 1\n",
            "large computational resources: 1\n",
            "computational resources natural: 1\n",
            "resources natural language: 1\n",
            "natural language processing: 1\n",
            "language processing helps: 1\n",
            "processing helps computers: 1\n",
            "helps computers understand: 1\n",
            "computers understand human: 1\n",
            "understand human language: 1\n",
            "human language medical: 1\n",
            "language medical diagnosis: 1\n",
            "medical diagnosis systems: 1\n",
            "diagnosis systems use: 1\n",
            "systems use probabilistic: 1\n",
            "use probabilistic models: 1\n",
            "probabilistic models for: 1\n",
            "models for decision: 1\n",
            "for decision making: 1\n",
            "decision making researchers: 1\n",
            "making researchers analyze: 1\n",
            "researchers analyze genomic: 1\n",
            "analyze genomic data: 1\n",
            "genomic data using: 1\n",
            "data using advanced: 1\n",
            "using advanced algorithms: 1\n",
            "advanced algorithms clinical: 1\n",
            "algorithms clinical decision: 1\n",
            "clinical decision support: 1\n",
            "decision support systems: 1\n",
            "support systems assist: 1\n",
            "systems assist doctors: 1\n",
            "assist doctors in: 1\n",
            "doctors in hospitals: 1\n",
            "in hospitals big: 1\n",
            "hospitals big data: 1\n",
            "big data analytics: 1\n",
            "data analytics enables: 1\n",
            "analytics enables faster: 1\n",
            "enables faster disease: 1\n",
            "faster disease detection: 1\n",
            "disease detection statistical: 1\n",
            "detection statistical models: 1\n",
            "statistical models are: 1\n",
            "models are essential: 1\n",
            "are essential for: 1\n",
            "essential for healthcare: 1\n",
            "for healthcare research: 1\n",
            "healthcare research computational: 1\n",
            "research computational linguistics: 1\n",
            "computational linguistics combines: 1\n",
            "linguistics combines computer: 1\n",
            "combines computer science: 1\n",
            "computer science and: 1\n",
            "science and linguistics: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "galDDB5MS7Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of\", next_word, \"is\", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "sequence1 = \"machine learning\"\n",
        "print(predict_next_word_bigram(sequence1, bigram_counts, unigram_counts))\n",
        "\n",
        "sequence2 = \"natural language\"\n",
        "print(predict_next_word_bigram(sequence2, bigram_counts, unigram_counts))\n",
        "sequence1 = \"Deep neural\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Medical diagnosis systems\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"Researchers analyze\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGCCLG0RS9K_",
        "outputId": "e53fa114-d48c-456a-8949-1efdfbfbe9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of algorithms is 1.0\n",
            "algorithms\n",
            "probability of processing is 0.5\n",
            "probability of medical is 0.5\n",
            "processing\n",
            "probability of networks is 1.0\n",
            "Given sequence: 'Deep neural', predicted next word: 'networks'\n",
            "probability of machine is 0.3333333333333333\n",
            "probability of use is 0.3333333333333333\n",
            "probability of assist is 0.3333333333333333\n",
            "Given sequence: 'Medical diagnosis systems', predicted next word: 'machine'\n",
            "probability of genomic is 1.0\n",
            "Given sequence: 'Researchers analyze', predicted next word: 'genomic'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ],
      "metadata": {
        "id": "nKk_SAQcZagU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSsZs63vVCuZ",
        "outputId": "bb545765-5e14-4ab6-ca38-1656e68fd94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textdeep\n",
            "probability of neural is 1.0\n",
            "Given sequence: 'deep', predicted next word: 'neural'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "OuNJ1w1PVOK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Artificial intelligence\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Machine learning\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4J3OdHMVRdJ",
        "outputId": "78128d20-ac6d-4417-936e-5eab28070953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  is is  1.0\n",
            "Given sequence: 'Artificial intelligence', predicted next word: 'is'\n",
            "probability of  algorithms is  1.0\n",
            "Given sequence: 'Machine learning', predicted next word: 'algorithms'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "5HxeEhc6VtZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgntdqUPVwOq",
        "outputId": "6d8f0dbd-8b30-4dec-ce8c-80e9c0423c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textmachine learning\n",
            "probability of  algorithms is  1.0\n",
            "Given sequence: 'machine learning', predicted next word: 'algorithms'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "UjlYZC5sV-os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Artificial intelligence\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Machine learning algorithms\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"Machine learning\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtbxYiAAWGST",
        "outputId": "ea7d46b7-f00e-48dc-b54b-15fa8656e518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of is is  0.03125\n",
            "Given sequence: 'Artificial intelligence', predicted next word: 'is'\n",
            "probability of improve is  0.03076923076923077\n",
            "probability of clinical is  0.03076923076923077\n",
            "Given sequence: 'Machine learning algorithms', predicted next word: 'improve'\n",
            "probability of algorithms is  0.03125\n",
            "Given sequence: 'Machine learning', predicted next word: 'algorithms'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "39y4D-lXWpee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT3mhxuQWtPv",
        "outputId": "11477b90-5db0-44db-c934-f008e74ea5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textmachine\n",
            "probability of learning is  0.03125\n",
            "Given sequence: 'machine', predicted next word: 'learning'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "z2eloyteXAfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Natural language processing\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Medical diagnosis systems\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnIy8GMPXDuT",
        "outputId": "570bf6be-3a73-4b08-8f40-bb938793d894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  helps is  0.03125\n",
            "Given sequence: 'Natural language processing', predicted next word: 'helps'\n",
            "probability of  use is  0.03125\n",
            "Given sequence: 'Medical diagnosis systems', predicted next word: 'use'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "PYupunEEX_8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx8LPgspYDQl",
        "outputId": "29602e2e-26ae-441a-e241-55bf0d99100c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textNLP\n",
            "Given sequence: 'NLP', predicted next word: 'Sequence must contain at least two words for trigram prediction.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "rrVoEvB-Y-OY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Researchers analyze\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Clinical decision support\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"Big data\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEq109ZfZApG",
        "outputId": "ff0fa507-c61d-4494-e58f-18d64434a5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of genomic is  0.046153846153846156\n",
            "Given sequence: 'Researchers analyze', predicted next word: 'genomic'\n",
            "probability of systems is  0.046153846153846156\n",
            "Given sequence: 'Clinical decision support', predicted next word: 'systems'\n",
            "probability of using is  0.04477611940298507\n",
            "probability of analytics is  0.04477611940298507\n",
            "Given sequence: 'Big data', predicted next word: 'using'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "aIYyRhwXaGKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq8ByzeXaJs3",
        "outputId": "008bd6a4-afe7-42e9-fa47-ea9fd3614863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textStatistical\n",
            "probability of models is  0.046153846153846156\n",
            "Given sequence: 'Statistical', predicted next word: 'models'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "J2fELWiOaRVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Big data analytics\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"Computational linguistics combines\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ-dP0yNaYqj",
        "outputId": "526707c4-a986-4452-deec-27d9104e8b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  enables is  0.046153846153846156\n",
            "Given sequence: 'Big data analytics', predicted next word: 'enables'\n",
            "probability of  computer is  0.046153846153846156\n",
            "Given sequence: 'Computational linguistics combines', predicted next word: 'computer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "SjNRHJr3axAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R5SO7Jqa04Z",
        "outputId": "2e86dc5d-520b-4ff0-886c-496d38ed9508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textComputational linguistics combines\n",
            "probability of  computer is  0.046153846153846156\n",
            "Given sequence: 'Computational linguistics combines', predicted next word: 'computer'\n"
          ]
        }
      ]
    }
  ]
}